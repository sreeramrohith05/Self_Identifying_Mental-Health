{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a52acbc-f414-45ee-9950-87941adce452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ds = pd.read_csv('datasetone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae24959f-2f96-4d0e-b33e-b3dd0df0168c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Ex Wife Threatening SuicideRecently I left my ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Am I weird I don't get affected by compliments...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Finally 2020 is almost over... So I can never ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>I‚Äôm so lostHello, my name is Adam (16) and I‚Äôv...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232069</th>\n",
       "      <td>348103</td>\n",
       "      <td>If you don't like rock then your not going to ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232070</th>\n",
       "      <td>348106</td>\n",
       "      <td>You how you can tell i have so many friends an...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232071</th>\n",
       "      <td>348107</td>\n",
       "      <td>pee probably tastes like salty teaüòèüí¶‚ÄºÔ∏è can som...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232072</th>\n",
       "      <td>348108</td>\n",
       "      <td>The usual stuff you find hereI'm not posting t...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232073</th>\n",
       "      <td>348110</td>\n",
       "      <td>I still haven't beaten the first boss in Hollo...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232074 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  \\\n",
       "0                2  Ex Wife Threatening SuicideRecently I left my ...   \n",
       "1                3  Am I weird I don't get affected by compliments...   \n",
       "2                4  Finally 2020 is almost over... So I can never ...   \n",
       "3                8          i need helpjust help me im crying so hard   \n",
       "4                9  I‚Äôm so lostHello, my name is Adam (16) and I‚Äôv...   \n",
       "...            ...                                                ...   \n",
       "232069      348103  If you don't like rock then your not going to ...   \n",
       "232070      348106  You how you can tell i have so many friends an...   \n",
       "232071      348107  pee probably tastes like salty teaüòèüí¶‚ÄºÔ∏è can som...   \n",
       "232072      348108  The usual stuff you find hereI'm not posting t...   \n",
       "232073      348110  I still haven't beaten the first boss in Hollo...   \n",
       "\n",
       "              class  \n",
       "0           suicide  \n",
       "1       non-suicide  \n",
       "2       non-suicide  \n",
       "3           suicide  \n",
       "4           suicide  \n",
       "...             ...  \n",
       "232069  non-suicide  \n",
       "232070  non-suicide  \n",
       "232071  non-suicide  \n",
       "232072      suicide  \n",
       "232073  non-suicide  \n",
       "\n",
       "[232074 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a36a6a-44b1-4c77-9154-658efd4fd749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                               text        class\n",
      "0           2  Ex Wife Threatening SuicideRecently I left my ...      suicide\n",
      "1           3  Am I weird I don't get affected by compliments...  non-suicide\n",
      "2           4  Finally 2020 is almost over... So I can never ...  non-suicide\n",
      "3           8          i need helpjust help me im crying so hard      suicide\n",
      "4           9  I‚Äôm so lostHello, my name is Adam (16) and I‚Äôv...      suicide\n"
     ]
    }
   ],
   "source": [
    "print(ds.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89539af4-4482-4e5a-982c-7a3316dbc170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 232074 entries, 0 to 232073\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  232074 non-null  int64 \n",
      " 1   text        232074 non-null  object\n",
      " 2   class       232074 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 5.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ds.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee769319-12a8-4f0a-9407-d21be5ca5aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Unnamed: 0\n",
      "count  232074.000000\n",
      "mean   174152.863518\n",
      "std    100500.425362\n",
      "min         2.000000\n",
      "25%     87049.250000\n",
      "50%    174358.500000\n",
      "75%    261285.750000\n",
      "max    348110.000000\n"
     ]
    }
   ],
   "source": [
    "print(ds.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e874bd49-3f4a-4282-a737-c458c06fadf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sreer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sreer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#data preprosessing steps\n",
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "#import emoji\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize necessary tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Define preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove emojis\n",
    "   # text = emoji.replace_emoji(text, replace='')\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35311d2a-8538-4517-bfda-e3b04ed5a978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ex wife threaten suiciderec left wife good che...\n",
      "1    weird dont get affect compliment come someon k...\n",
      "2    final 2020 almost never hear 2020 bad year eve...\n",
      "3                       need helpjust help im cri hard\n",
      "4    ‚Äô losthello name adam 16 ‚Äô struggl year ‚Äô afra...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to the text column\n",
    "ds['text'] = ds['text'].apply(preprocess_text)\n",
    "\n",
    "# Display the processed text\n",
    "print(ds['text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39efc3a3-9df1-4a33-8672-f5cf8ffce416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sreer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sreer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11dba0db-505b-4a6c-bdaf-3148ef67b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcccf591-f0f1-491c-80ed-3c2c616e2f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the processed text data\n",
    "X = tfidf_vectorizer.fit_transform(ds['text'])\n",
    "y = ds['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89430938-f18b-46b9-8f72-4e593e1da00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b5714f8-4e4c-425e-9576-6257812fb41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9315307551438112\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d81e1be8-77e9-4e04-8a9b-ee5466464bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "pickle.dump(tfidf_vectorizer,open('vector.pkl','wb'))\n",
    "pickle.dump(model,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2eb92c6e-97b0-4891-ba7a-8cc180df2c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "# Streamlit app\n",
    "st.title(\"Mental Health Text Classification\")\n",
    "\n",
    "# User input\n",
    "user_input = st.text_area(\"Enter a message to analyze:\")\n",
    "\n",
    "# Preprocess user input\n",
    "preprocessed_input = preprocess_text(user_input)\n",
    "input_vector = tfidf_vectorizer.transform([preprocessed_input])\n",
    "\n",
    "# Make predictions with both models\n",
    "prediction_log_reg = model.predict(input_vector)\n",
    "\n",
    "st.header(\"Prediction using Logistic Regression:\")\n",
    "if prediction_log_reg[0] == 1:\n",
    "    st.header(\"The message indicates a mental health issue.\")\n",
    "    st.write(\"Please consult a doctor.\")\n",
    "else:\n",
    "    st.header(\"The message does not indicate a mental health issue.\")\n",
    "    st.write(\"You are very happy. Keep going!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3199581a-2cc8-4963-8886-dad21e16834b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
